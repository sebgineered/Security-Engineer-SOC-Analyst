import os
import re
from collections import defaultdict
from docx import Document
import json

# Function to extract IP addresses from a Word document
def extract_ips_from_docx(file_path):
    ips = set()
    try:
        doc = Document(file_path)
        for paragraph in doc.paragraphs:
            # Use regex to extract IPv4 addresses
            matches = re.findall(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', paragraph.text)
            ips.update(matches)
    except Exception as e:
        print(f"Error reading file {file_path}: {e}")
    return ips

# Main function to process documents and find duplicates
def find_duplicate_ips(directory):
    ip_count = defaultdict(int)  # Count occurrences of each IP
    file_ips = defaultdict(set)  # Track which files contain each IP

    # Iterate through all Word documents in the directory
    for file_name in os.listdir(directory):
        if file_name.endswith(".docx"):
            file_path = os.path.join(directory, file_name)
            print(f"Processing file: {file_path}")
            ips = extract_ips_from_docx(file_path)
            for ip in ips:
                ip_count[ip] += 1
                file_ips[ip].add(file_name)

    # Find IPs that appear in at least two files
    duplicate_ips = {ip: list(files) for ip, files in file_ips.items() if len(files) > 1}

    return duplicate_ips

# Define the directory containing the Word documents
directory_path = "/home/kali/Documents/Project/IOC"  # Update this path if needed

# Find duplicate IPs
duplicates = find_duplicate_ips(directory_path)

# Save the results to a JSON file
output_file = os.path.join(directory_path, "duplicate_ips.json")
with open(output_file, "w") as f:
    json.dump(duplicates, f, indent=4)
print(f"\nResults saved to {output_file}")

# Print the results to the console
if duplicates:
    print("\nIPs found in at least two files:")
    for ip, files in duplicates.items():
        print(f"{ip}: Found in {', '.join(files)}")
else:
    print("No duplicate IPs found.")
